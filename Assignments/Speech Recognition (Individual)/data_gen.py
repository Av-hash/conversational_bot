# -*- coding: utf-8 -*-
"""Data_Gen.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JhZbv8ahULgkMeq0CntdKXCzaRPctQA5
"""

!pip install pysoundfile

char_map_str = """
' 1
<SPACE> 2
A 3
B 4
C 5
D 6
E 7
F 8
G 9
H 10
I 11
J 12
K 13
L 14
M 15
N 16
O 17
P 18
Q 19
R 20
S 21
T 22
U 23
V 24
W 25
X 26
Y 27
Z 28
"""
char_map = {}
index_map = {}
for line in char_map_str.strip().split('\n'):
    ch, index = line.split()
    char_map[ch] = int(index)
    index_map[int(index)] = ch
index_map[2] = ' '
print(char_map)

from numpy.lib.stride_tricks import as_strided
import soundfile
from matplotlib import pyplot as plt
def spectrogram_graph(samples, fft_length=256, sample_rate=2, hop_length=128):

    assert not np.iscomplexobj(samples), "Must not pass in complex numbers"

    window = np.hanning(fft_length)[:, None]
    window_norm = np.sum(window**2)

    scale = window_norm * sample_rate

    trunc = (len(samples) - fft_length) % hop_length
    x = samples[:len(samples) - trunc]

    nshape = (fft_length, (len(x) - fft_length) // hop_length + 1)
    nstrides = (x.strides[0], x.strides[0] * hop_length)
    x = as_strided(x, shape=nshape, strides=nstrides)

    assert np.all(x[:, 1] == samples[hop_length:(hop_length + fft_length)])
    x = np.fft.rfft(x * window, axis=0)
    x = np.absolute(x)**2
    x[1:-1, :] *= (2.0 / scale)
    x[(0, -1), :] /= scale

    freqs = float(sample_rate) / fft_length * np.arange(x.shape[0])

    return x, freqs

# Commented out IPython magic to ensure Python compatibility.
# %%bash
# mkdir test-clean
# tar -xvf '/content/test-clean.tar.gz' -C '/content/'

import os
import linecache
import numpy as np
import pandas as pd
def spectrogram_from_file(filename, step=10, window=20, max_freq=None,
                          eps=1e-14,input_length=400000):
    with soundfile.SoundFile(filename) as sound_file:
        audio = sound_file.read(dtype='float32')
        if len(audio)>input_length:
            audio = audio[:input_length]
        else:
            audio = np.pad(audio, (0, max(0, input_length - len(audio))), "constant")
        sample_rate = sound_file.samplerate
        if audio.ndim >= 2:
            audio = np.mean(audio, 1)
        if max_freq is None:
            max_freq = sample_rate / 2
        if max_freq > sample_rate / 2:
            raise ValueError("max_freq must not be greater than half of "
                             " sample rate")
        if step > window:
            raise ValueError("step size must not be greater than window size")
        hop_length = int(0.001 * step * sample_rate)
        fft_length = int(0.001 * window * sample_rate)
        pxx, freqs = spectrogram_graph(
            audio, fft_length=fft_length, sample_rate=sample_rate,
            hop_length=hop_length)
        ind = np.where(freqs <= max_freq)[0][-1] + 1
        spec=np.transpose(np.log(pxx[:ind, :] + eps))
    
    return spec
def load_data():
    data=[]
    for speaker in os.listdir("/content/LibriSpeech/test-clean/"):
        for chapter in os.listdir("/content/LibriSpeech/test-clean/"+speaker):
            for filename in os.listdir("/content/LibriSpeech/test-clean/"+speaker+"/"+chapter):
                if filename.endswith(".flac"):
                    line = linecache.getline("/content/LibriSpeech/test-clean/"+speaker+"/"+chapter+"/"+"".join(list(filename)[:-10])+".trans.txt", int("".join(list("".join(list(filename)[:-5]))[-4:]))+1)
                    source="/content/LibriSpeech/test-clean/"+speaker+"/"+chapter+"/"+filename
                    sample=(source,line)
                    data.append(sample)
    return data
 
def process_file(sample):
    source,transcript=sample
    #print(transcript)
    transcript=transcript.split(' ',1)[1]
    #print(transcript)
    #print(source)
    line_to_index=[]
    for character in list(transcript)[:-1]:
        if character==' ':
                character='<SPACE>'
        line_to_index.append(char_map[character])
    processed_input=(spectrogram_from_file(source),line_to_index)
    return processed_input

import os
data=load_data()
print(len(data))
print(data[0])
spec,text=process_file(data[0])
print(np.shape(text))
print(text)
print(spec.shape)
plt.imshow(np.transpose(spec))
#print(source)
#print(transcript)

import numpy as np
import keras
 
class DataGenerator(keras.utils.Sequence):
    'Generates data for Keras'
    def __init__(self, dim=(2499,161), batch_size=32, n_classes=10,
                 n_channels=1, shuffle=True):
        'Initialization'
        self.dim = dim
        self.batch_size = batch_size
        self.data=data
        self.data=load_data()
        self.list_IDs = np.arange(len(data))
        self.n_channels = n_channels
        self.n_classes = n_classes
        self.shuffle = shuffle
        self.on_epoch_end()
 
    def __len__(self):
        'Denotes the number of batches per epoch'
        return int(np.floor(len(self.list_IDs) / self.batch_size))
 
    def __getitem__(self, index):
        'Generate one batch of data'
        # Generate indexes of the batch
        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]
 
        # Find list of IDs
        list_IDs_temp = [self.list_IDs[k] for k in indexes]
 
        # Generate data
        X, y = self.__data_generation(list_IDs_temp)
 
        return X, y
        
 
    def on_epoch_end(self):
        'Updates indexes after each epoch'
        self.indexes = np.arange(len(self.list_IDs))
        if self.shuffle == True:
            np.random.shuffle(self.indexes)
 
    def __data_generation(self, list_IDs_temp):
        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)
        # Initialization
        X = np.empty((self.batch_size, *self.dim))
        Y = np.empty((self.batch_size), dtype=list)
 
        # Generate data
        for i, ID in enumerate(list_IDs_temp):
            # Store sample
            x,y=process_file(self.data[i])
            #print(y)
            X[i,]=x
            Y[i]=y
            # Store class
        X=np.asarray(X)
        Y=np.asarray(Y)
        return X,Y

params = {'dim': (2499,161),
          'batch_size': 64,
          'n_classes': 6,
          'n_channels': 1,
          'shuffle': True}

# Generators
training_generator = DataGenerator(**params)

X,Y=training_generator.__getitem__(0)

print(Y[0])

plt.imshow(np.transpose(X[0]))

