# -*- coding: utf-8 -*-
"""Speech_Rec.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Uk60M-nVnoGFDwwrLLKvq4LrDRJQv5Ty
"""

!pip install pysoundfile

import tensorflow as tf

char_map_str = """
' 1
<SPACE> 2
A 3
B 4
C 5
D 6
E 7
F 8
G 9
H 10
I 11
J 12
K 13
L 14
M 15
N 16
O 17
P 18
Q 19
R 20
S 21
T 22
U 23
V 24
W 25
X 26
Y 27
Z 28
"""
char_map = {}
index_map = {}
for line in char_map_str.strip().split('\n'):
    ch, index = line.split()
    char_map[ch] = int(index)
    index_map[int(index)] = ch
index_map[2] = ' '
print(char_map)

from numpy.lib.stride_tricks import as_strided
import soundfile
from matplotlib import pyplot as plt
def spectrogram_graph(samples, fft_length=256, sample_rate=2, hop_length=128):

    assert not np.iscomplexobj(samples), "Must not pass in complex numbers"

    window = np.hanning(fft_length)[:, None]
    window_norm = np.sum(window**2)

    scale = window_norm * sample_rate

    trunc = (len(samples) - fft_length) % hop_length
    x = samples[:len(samples) - trunc]

    nshape = (fft_length, (len(x) - fft_length) // hop_length + 1)
    nstrides = (x.strides[0], x.strides[0] * hop_length)
    x = as_strided(x, shape=nshape, strides=nstrides)

    assert np.all(x[:, 1] == samples[hop_length:(hop_length + fft_length)])
    x = np.fft.rfft(x * window, axis=0)
    x = np.absolute(x)**2
    x[1:-1, :] *= (2.0 / scale)
    x[(0, -1), :] /= scale

    freqs = float(sample_rate) / fft_length * np.arange(x.shape[0])

    return x, freqs

# Commented out IPython magic to ensure Python compatibility.
# %%bash
# mkdir test-clean
# tar -xvf '/content/test-clean.tar.gz' -C '/content/'

import os
import linecache
import numpy as np
import pandas as pd
def spectrogram_from_file(filename, step=10, window=20, max_freq=None,
                          eps=1e-14,input_length=400000):
    with soundfile.SoundFile(filename) as sound_file:
        audio = sound_file.read(dtype='float32')
        if len(audio)>input_length:
            audio = audio[:input_length]
        else:
            audio = np.pad(audio, (0, max(0, input_length - len(audio))), "constant")
        sample_rate = sound_file.samplerate
        if audio.ndim >= 2:
            audio = np.mean(audio, 1)
        if max_freq is None:
            max_freq = sample_rate / 2
        if max_freq > sample_rate / 2:
            raise ValueError("max_freq must not be greater than half of "
                             " sample rate")
        if step > window:
            raise ValueError("step size must not be greater than window size")
        hop_length = int(0.001 * step * sample_rate)
        fft_length = int(0.001 * window * sample_rate)
        pxx, freqs = spectrogram_graph(
            audio, fft_length=fft_length, sample_rate=sample_rate,
            hop_length=hop_length)
        ind = np.where(freqs <= max_freq)[0][-1] + 1
        spec=np.transpose(np.log(pxx[:ind, :] + eps))
    
    return spec
def load_data():
    data=[]
    for speaker in os.listdir("/content/LibriSpeech/test-clean/"):
        for chapter in os.listdir("/content/LibriSpeech/test-clean/"+speaker):
            for filename in os.listdir("/content/LibriSpeech/test-clean/"+speaker+"/"+chapter):
                if filename.endswith(".flac"):
                    line = linecache.getline("/content/LibriSpeech/test-clean/"+speaker+"/"+chapter+"/"+"".join(list(filename)[:-10])+".trans.txt", int("".join(list("".join(list(filename)[:-5]))[-4:]))+1)
                    source="/content/LibriSpeech/test-clean/"+speaker+"/"+chapter+"/"+filename
                    sample=(source,line)
                    data.append(sample)
    return data
 
def process_file(sample,max_len=500):
    source,transcript=sample
    #print(transcript)
    transcript=transcript.split(' ',1)[1]
    #print(transcript)
    #print(source)
    line_to_index=[]
    for character in list(transcript)[:-1]:
        if character==' ':
                character='<SPACE>'
        line_to_index.append(char_map[character])
    if len(line_to_index)>=500:
        line_to_index=line_to_index[:500]
    else:
        while len(line_to_index)<500:
            line_to_index.append(2)
    processed_input=(spectrogram_from_file(source),np.array(line_to_index))
    return processed_input

data=load_data()
print(len(data))
print(data[0][0])
spec,text=process_file(data[8])
print(text)
print(np.shape(text))
print(time)
print(size)
plt.imshow(np.transpose(spec))
print(spec.shape)
#print(source)
#print(transcript)

import numpy as np
import keras
 
class DataGenerator(keras.utils.Sequence):
    'Generates data for Keras'
    def __init__(self, dim=(2499,161), batch_size=32, shuffle=True):
        'Initialization'
        self.dim = dim
        self.batch_size = batch_size
        self.shuffle=shuffle
        self.data=data
        self.data=load_data()
        self.list_IDs = np.arange(len(self.data))
        self.on_epoch_end()
      
 
    def __len__(self):
        'Denotes the number of batches per epoch'
        return int(np.floor(len(self.list_IDs) / self.batch_size))
 
    def __getitem__(self, index):
        'Generate one batch of data'
        # Generate indexes of the batch
        indexes = self.indexes[index*self.batch_size//2:(index+1)*self.batch_size//2]
 
        # Find list of IDs
        list_IDs_temp = [self.list_IDs[k] for k in indexes]
 
        # Generate data
        X, y = self.__data_generation(list_IDs_temp)
        input_shape=np.zeros([self.batch_size,1])
        label_length=np.zeros([self.batch_size,1])
        input_shape[:]=2499
        label_length[:]=500
        inputs={
            'the_inputs': X,
            'the_labels': y,
            'input_length': input_shape,
            'label_length': label_length
        }
        outputs={'ctc': y}
 
        return (inputs,outputs)
        
 
    def on_epoch_end(self):
        'Updates indexes after each epoch'
        self.indexes = np.arange(len(self.list_IDs))
        if self.shuffle == True:
            np.random.shuffle(self.indexes)
 
    def __data_generation(self, list_IDs_temp):
        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)
        # Initialization
        X = np.empty((self.batch_size, *self.dim))
        Y = np.empty((self.batch_size,500), dtype='int32')
        input_length=[]
        label_length=[]
        for i, ID in enumerate(list_IDs_temp):
            x,y=process_file(self.data[i])
            X[i,]=x
            Y[i,]=y 
        #X=np.asarray(X)
        #Y=np.asarray(Y)
        return X,Y

params = {'dim': (2499,161),
          'batch_size': 64,
          'shuffle': True}

# Generators
training_generator = DataGenerator(**params)

X,Y=training_generator.__getitem__(0)

print(X['the_labels'][0])
print(X['the_inputs'].shape,X['the_labels'].shape)

#plt.imshow(np.transpose(X['the_inputs'][0]))
print(Y['ctc'][0])

from tensorflow.keras import Model
from tensorflow.keras.layers import Conv1D,BatchNormalization,GRU,TimeDistributed,Input,Flatten,Bidirectional,Dense,Lambda

def ctc_lambda(args):
  y_pred,labels,input_length,label_length=args
  return tf.keras.backend.ctc_batch_cost(labels,y_pred,input_length,label_length)

GAMMA=0.997
EPSILON=1e-3
def mymodel(input_shape,conv_layer_count,rnn_layer_count):
  input_data = Input(shape=(2499,161), name="the_inputs")
  X = Conv1D(filters=128, kernel_size=11, activation='relu', padding="valid")(input_data)
  for _ in range(conv_layer_count-1):
    X = Conv1D(filters=128, kernel_size=11, activation='relu', padding="valid")(X)
  print (X.shape)
  X=tf.keras.layers.BatchNormalization(momentum=GAMMA,epsilon=EPSILON)(X)
  print (X.shape)
  for _ in range(rnn_layer_count):
    X = Bidirectional(GRU(units=256, activation='relu', return_sequences=True))(X)
  print (X.shape)
  X=tf.keras.layers.BatchNormalization(momentum=GAMMA,epsilon=EPSILON)(X)
  print (X.shape)
  X = TimeDistributed(Dense(units=29, activation="softmax"))(X)
  print (X.shape)
  labels = Input(name='the_labels', shape=[500,], dtype='int32')
  input_length = Input(name='input_length', shape=[1], dtype='int32')
  label_length = Input(name='label_length', shape=[1], dtype='int32')

  loss = Lambda(ctc_lambda, output_shape=(1,), name='ctc')([X,
                                                                labels,
                                                                input_length,
                                                                label_length])

  model = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss)
  return model

model=mymodel((2499,161),1,1)
model.compile(loss=lambda ytrue,ypred:ypred,optimizer='adam',metrics=['accuracy'])
model.summary()

model.fit_generator(generator=training_generator,epochs=2)

